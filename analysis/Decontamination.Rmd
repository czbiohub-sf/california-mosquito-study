---
title: "R Notebook"
output: html_notebook
---

```{r}
knitr::opts_chunk$set(root.dir='~/src/skeeters')
library(taxizedb)
library(tidyverse)
library(purrr)
library(ggplot2)
library(decontam)
library(forcats)
```

```{r}
data_dir = '~/src/skeeters/data'
```

```{r}
sample_table = read_csv(file.path(data_dir, 'metadata/idseq_metadata.csv'))
head(sample_table)
```

Approximate input concentration (up to a constant factor) by ratio of reads to ERCCs.

```{r}
sample_table = sample_table %>% mutate(water = str_detect(sample, 'ater')) %>%
  select(sample, total_reads, nonhost_reads, total_ercc_reads, compression_ratio, water) %>%
  mutate(input_conc = (total_reads - total_ercc_reads)/total_ercc_reads, nonhost_frac = nonhost_reads*compression_ratio/total_reads)
```

Load reads-mapping-to-contigs, together with contig LCAs.

```{r}
contig_reads = read_tsv(file.path(data_dir, 's3/contig_quality_concat/contig_stats_lca.tsv'))
contig_reads = contig_reads %>% filter(!hexapoda) %>% filter(!is.na(taxid))
read_counts = contig_reads %>% group_by(taxid, sample) %>% summarize(reads = sum(read_count))
```

Markov correction for background. We compute the average concentration of each taxon in the water. Markov's inequality says that for any nonnegative random variable X, the probability that X is greater k is less than EX/k. Thus for any false-discovery rate r, the probability that X > EX/r is less than EX/(EX/r) = r. If we treat concentrations of contaminating taxa in each well as a random variable, we can estimate the mean from the water, and use that estimate to bound (using Markov's inequality), the amount of that taxon contained in another sample can be explained by contamination.

```{r}
decontam <- function(read_counts, category, fdr){
  n_water = length(sample_table %>% filter(water))

  background_levels = read_counts %>% left_join(sample_table, by='sample') %>% filter(water) %>%
    mutate(r_per_ercc = reads*compression_ratio/total_ercc_reads) %>%
    group_by(!!category) %>% summarize(background_rate = sum(r_per_ercc)/n_water)

  df = read_counts %>% left_join(sample_table, by='sample') %>% filter(!water) %>%
    left_join(background_levels, by=quo_name(category))  %>%
    replace_na(list(background_rate = 0)) %>%  mutate(background_reads=total_ercc_reads*background_rate/compression_ratio) 
    
  df %>% mutate(is_contam = (reads < background_reads/fdr)) %>% 
    select(sample, !!category, reads, background_reads, is_contam)
}
```

```{r}
sum_over <- function(df, category){
  df %>% select(!!category, sample, read_count) %>% 
    group_by(!!category, sample) %>% summarize(reads = sum(read_count))
}
```

```{r}
category = quo(taxid)

df = decontam(sum_over(contig_reads, category),
         category, 0.01)

decontam_read_counts = df %>% filter(!is_contam) %>% select(sample, taxid, reads)

contamination = df %>% filter(is_contam) %>% select(sample, taxid, reads, background_reads)
contamination %>% write_tsv(file.path(data_dir, 's3/contig_quality_concat/sample_contamination.tsv'))
decontam_read_counts %>% write_tsv(file.path(data_dir, 's3/contig_quality_concat/decontam_sample_read_counts.tsv'))
```

# Exploratory Analysis


Hubei MV 2: 1922926
Wuhan 6: 1608131
Wuhan 9: 1608134
narna: 1628188
culex iflavi-like virus 4: 2304480
mouse: 10090

Plot relationship of relative abundance (RPM) to input RNA concentration. For contaminants, this should be approx linear.

```{r}
contig_reads %>% filter(taxid == '1248439')
```


```{r}
contig_reads %>% filter((taxid == '10090') & (sample == 'CMS001_002_Ra_S1'))
read_counts %>% filter((taxid == '10090'))
read_counts %>% left_join(sample_table, by='sample') %>% mutate(rpm = reads/total_reads*1e6) %>%
  select(sample, taxid, input_conc, rpm, water, total_ercc_reads, reads) %>%
    filter((taxid == '10090'))
```


```{r}
read_counts %>% left_join(sample_table, by='sample') %>% mutate(rpm = reads/total_reads*1e6) %>%
  select(sample, taxid, input_conc, rpm, water, total_ercc_reads, reads) %>%
    filter((taxid == '10090')) %>%
ggplot(aes(x = log10(input_conc), y=log10(rpm), color=water)) + geom_point()
```



What was removed as contamination?

```{r}
contamination %>% group_by(taxid) %>% summarize(n_samples = n(), n_reads = sum(reads)) %>% arrange(desc(n_samples))
```



# Curated Viruses

```{r}
all_contig_reads = read_tsv(file.path(data_dir, 's3/contig_quality_concat/contig_stats_all.tsv'))
all_contig_reads = all_contig_reads %>% mutate(key = str_c(sample, "|", contig_name))
```

```{r}
cluster_to_virus = read_csv('../data/darkmatter/clusters_to_virus.csv')
```


```{r}
cluster_contig = read_csv('../data/darkmatter/cluster_contig.csv')
cluster_contig = cluster_contig %>% mutate(key = str_c(sample, "|", contig))
cluster_contig = cluster_contig %>% left_join(cluster_to_virus, on='cluster') %>% filter(!is.na(name))

contigs_in_clusters = cluster_contig %>% pull(key)
all_contig_reads = all_contig_reads %>% filter(key %in% contigs_in_clusters) %>% select(key, read_count)

cluster_contig = cluster_contig %>% left_join(all_contig_reads, on='key')

read_counts = cluster_contig %>% select(cluster, sample, read_count) %>% group_by(cluster, sample) %>% summarize(reads = sum(read_count))
```


```{r}
category = quo(poly_group)

viral_contamination = decontam(sum_over(cluster_contig, category), category, 0.01) %>% 
  filter(is_contam) %>% select(sample, poly_group, reads, background_reads) 

viral_contamination %>% write_tsv(file.path(data_dir, 's3/contig_quality_concat/viral_contamination.tsv'))
```

```{r}
viral_contamination
```


```{r}
category = quo(provisional_name)

decontam(sum_over(cluster_contig, category),
         category, 0.01) %>% filter(is_contam)
```
