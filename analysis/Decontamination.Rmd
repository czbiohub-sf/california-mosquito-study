---
title: "R Notebook"
output: html_notebook
---

```{r}
knitr::opts_chunk$set(root.dir='~/src/skeeters')
library(tidyverse)
library(purrr)
library(ggplot2)
library(forcats)
```

```{r}
data_dir = '~/src/skeeters/data'
```

```{r}
sample_table = read_csv(file.path(data_dir, 'metadata/idseq_metadata.csv'))
head(sample_table)
```

Approximate input concentration (up to a constant factor) by ratio of reads to ERCCs.

```{r}
sample_table = sample_table %>% mutate(water = str_detect(sample, 'ater')) %>%
  select(sample, total_reads, nonhost_reads, total_ercc_reads, compression_ratio, water) %>%
  mutate(input_conc = (total_reads - total_ercc_reads)/total_ercc_reads, nonhost_frac = nonhost_reads*compression_ratio/total_reads)
```

Load reads-mapping-to-contigs, together with contig LCAs.

```{r}
contig_reads = read_tsv(file.path(data_dir, 's3/contig_quality_concat/contig_stats_lca.tsv'))
contig_reads = contig_reads %>% filter(!hexapoda) %>% filter(!is.na(taxid)) %>% mutate(key = str_c(sample, "|", contig_name))
contig_reads
```

Load viral-reclassifications.

```{r}
all_contig_reads = read_tsv(file.path(data_dir, 's3/contig_quality_concat/contig_stats_all.tsv'))
all_contig_reads = all_contig_reads %>% mutate(key = str_c(sample, "|", contig_name))
```

```{r}
cluster_to_virus = read_csv('../data/darkmatter/clusters_to_virus.csv')
```

Add reads counts for viruses.

```{r}
cluster_contig = read_csv('../data/darkmatter/cluster_contig.csv')
cluster_contig = cluster_contig %>% mutate(key = str_c(sample, "|", contig))
cluster_contig = cluster_contig %>% left_join(cluster_to_virus, on='cluster') %>% filter(!is.na(name))

contigs_in_clusters = cluster_contig %>% pull(key)
all_contig_reads = all_contig_reads %>% filter(key %in% contigs_in_clusters) %>% select(key, read_count)

cluster_contig = cluster_contig %>% left_join(all_contig_reads, on='key')
```

Reassign taxids for curated viral contigs.

```{r}
contig_reads = contig_reads %>% full_join(cluster_contig %>% select(key, submission_taxid, sample, read_count)) %>% mutate(taxid = ifelse(is.na(submission_taxid), taxid, submission_taxid))
```

## Assessment of taxon reassignment

Contigs whose LCAs were in the following taxon_groups were reassigned:

```{r}
contig_reads %>% filter(!is.na(submission_taxid)) %>% group_by(taxon_group) %>% summarize(contigs = n(), reads = sum(read_count))
```

Contigs identified by BLAST alone, not modified by viral analysis.

```{r}
contig_reads %>% filter(is.na(submission_taxid)) %>% group_by(taxon_group) %>% summarize(contigs = n(), reads = sum(read_count))
```

Total classified contigs.

```{r}
contig_reads %>% summarize(contigs = n(), reads = sum(read_count))
```

Total curated viral contigs.
```{r}
contig_reads %>% filter(!is.na(submission_taxid)) %>% summarize(contigs = n(), reads = sum(read_count))
```

Total curated viral reads, dark and LCA, before decontamination.

```{r}
contig_reads %>% filter(!is.na(submission_taxid)) %>% 
  mutate(dark = is.na(taxon_group)) %>% group_by(dark) %>% summarize(reads = sum(read_count))
```

# Markov correction for background

We compute the average concentration of each taxon in the water. Markov's inequality says that for any nonnegative random variable X, the probability that X is greater k is less than EX/k. Thus for any false-discovery rate r, the probability that X > EX/r is less than EX/(EX/r) = r. If we treat concentrations of contaminating taxa in each well as a random variable, we can estimate the mean from the water, and use that estimate to bound (using Markov's inequality), the amount of that taxon contained in another sample can be explained by contamination.

```{r}
decontam <- function(read_counts, category, fdr){
  n_water = length(sample_table %>% filter(water))

  background_levels = read_counts %>% left_join(sample_table, by='sample') %>% filter(water) %>%
    mutate(r_per_ercc = reads*compression_ratio/total_ercc_reads) %>%
    group_by(!!category) %>% summarize(background_rate = sum(r_per_ercc)/n_water)

  df = read_counts %>% left_join(sample_table, by='sample') %>% filter(!water) %>%
    left_join(background_levels, by=quo_name(category))  %>%
    replace_na(list(background_rate = 0)) %>%  mutate(background_reads=total_ercc_reads*background_rate/compression_ratio) 
    
  df %>% mutate(is_contam = (reads < background_reads/fdr))
}
```

```{r}
sum_over <- function(df, category){
  df %>% select(!!category, sample, read_count) %>% 
    group_by(!!category, sample) %>% summarize(reads = sum(read_count))
}
```

Estimate contaminant taxa for curated viruses.

```{r}
category = quo(poly_group)

viral_df = decontam(sum_over(cluster_contig, category), category, 0.01)

viral_decontamination = viral_df %>% filter(!is_contam) %>% select(sample, poly_group, reads)
viral_decontamination %>% write_tsv(file.path(data_dir, 's3/contig_quality_concat/viral_decontam.tsv'))

viral_contamination = viral_df %>% filter(is_contam) %>% select(sample, poly_group, reads)
viral_contamination %>% write_tsv(file.path(data_dir, 's3/contig_quality_concat/viral_contamination.tsv'))

```

Viral contamination: 2757 reads.

```{r}
viral_df %>% group_by(is_contam) %>% summarize(reads = sum(reads))
```

Estimate contaminants which are not curated viruses.

```{r}
category = quo(taxid)

sample_taxid_reads = sum_over(contig_reads, category) %>% mutate(sample_taxid = str_c(sample, "|", taxid))

bad_pairs = decontam(sample_taxid_reads, category, 0.01) %>% filter(is_contam) %>% pull(sample_taxid)

contig_reads_no_polygroup = sum_over(contig_reads %>% filter(is.na(submission_taxid)), category) %>% 
  mutate(sample_taxid = str_c(sample, "|", taxid), is_contam=sample_taxid %in% bad_pairs)

lca_contamination = contig_reads_no_polygroup %>% filter(is_contam) %>% select(sample, taxid, reads)
lca_decontamination = contig_reads_no_polygroup %>% filter(!is_contam) %>% select(sample, taxid, reads)

lca_decontamination %>% write_tsv(file.path(data_dir, 's3/contig_quality_concat/lca_decontam.tsv'))
lca_contamination %>% write_tsv(file.path(data_dir, 's3/contig_quality_concat/lca_contamination.tsv'))
```

## Assessment of contamination

LCA contamination assessment: 43846 reads removed.

```{r}
contig_reads_no_polygroup %>% group_by(is_contam) %>% summarize(reads = sum(reads))
```

Decomposition of contamination by taxon.

```{r}
contig_reads_no_polygroup %>% filter(is_contam) %>% group_by(taxid) %>% summarize(reads = sum(reads)) %>% arrange(desc(reads))
```

Decomposition of contamination by sample.

```{r}
contig_reads_no_polygroup %>% filter(is_contam) %>% group_by(sample) %>% summarize(reads = sum(reads)) %>% arrange(desc(reads))
```



