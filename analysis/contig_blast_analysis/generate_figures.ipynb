{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ete3 import NCBITaxa\n",
    "import boto3\n",
    "import tempfile\n",
    "import subprocess\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "ncbi = NCBITaxa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_qcov_threshold = 0.9\n",
    "min_total_contig_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load metadata\n",
    "metadata = pd.read_csv(\"../../data/metadata/CMS001_CMS002_MergedAnnotations.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read counts data\n",
    "all_read_counts = pd.read_csv(\"s3://czbiohub-mosquito/contig_quality_concat/contig_counts.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "contig_stats_lca = pd.read_csv(\"s3://czbiohub-mosquito/contig_quality_concat/contig_stats_lca.tsv\", sep=\"\\t\", header=0)\n",
    "contig_stats_lca = contig_stats_lca.assign(identity_qcov=(contig_stats_lca[\"identity\"]/100*contig_stats_lca[\"align_length\"]/contig_stats_lca[\"contig_length\"]).apply(lambda x: min(x, 1)))\n",
    "contig_stats_lca = contig_stats_lca[~(contig_stats_lca[\"hexapoda\"] | contig_stats_lca[\"taxid\"].isnull())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_stats_lca = pd.merge(pd.merge(contig_stats_lca, metadata, how=\"left\", left_on=\"sample\", right_on=\"NewIDseqName\"), \n",
    "                            all_read_counts.groupby(\"sample\").sum().reset_index().rename(columns={\"counts\":\"total_nonhost\"}),\n",
    "                           how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_stats_lca[\"read_prop\"] = contig_stats_lca[\"read_count\"]/contig_stats_lca[\"total_nonhost\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_taxid (df, taxid, taxid_colname=\"taxid\", identity_qcov_cutoff=None):\n",
    "    if (not isinstance(df, pd.DataFrame)):\n",
    "        return (taxid in ncbi.get_lineage(df))\n",
    "    outdf = df[df[taxid_colname].apply(get_rows_taxid, taxid=taxid)]\n",
    "    if identity_qcov_cutoff is not None:\n",
    "        outdf = outdf[outdf[\"identity_qcov\"]>=identity_qcov_cutoff]\n",
    "    return (outdf)\n",
    "\n",
    "def filter_using_water_by_criterion (df, colname, split_by_taxid=True):\n",
    "    if (len(df)==0):\n",
    "        return (df)\n",
    "    if split_by_taxid:\n",
    "        water_counts = df[df[\"sample\"].apply(lambda x: \"ater\" in x)].groupby([\"taxid\", \"sample\"])[colname].sum().reset_index().groupby(\"taxid\").max()\n",
    "        df_groupby = df.groupby([\"taxid\", \"sample\"])\n",
    "        sample_sums = df_groupby[colname].sum().reset_index()\n",
    "        for i, x in enumerate(water_counts[colname]):\n",
    "            sample_sums[\"tokeep\"] = sample_sums.loc[sample_sums[\"taxid\"]==water_counts.index[i], colname] > x\n",
    "            df = pd.merge(df, sample_sums.drop(columns=colname), how=\"left\")\n",
    "            df = df[df[\"tokeep\"]!=False].drop(columns=\"tokeep\")\n",
    "    else:\n",
    "        metrics = df.groupby(\"sample\")[colname].sum().sort_values()\n",
    "        selected_samples = metrics.index[([i for i, x in enumerate(metrics.index) if 'ater' in x][-1]+1):]\n",
    "        df = df[df[\"sample\"].isin(selected_samples)]\n",
    "    return (df)\n",
    "    \n",
    "def use_water_filter (df, by_read_count=True, by_length=True, split_by_taxid=True):\n",
    "    if (not df[\"sample\"].apply(lambda x: \"ater\" in x).any()):\n",
    "        return (df)\n",
    "    if split_by_taxid:\n",
    "        if (by_read_count):\n",
    "            df = filter_using_water_by_criterion(df, \"read_count\", split_by_taxid)\n",
    "        if (by_length):\n",
    "            df = filter_using_water_by_criterion(df, \"contig_length\", split_by_taxid)\n",
    "    else:\n",
    "        if (by_read_count):\n",
    "            filter_using_water_by_criterion(df, \"read_count\", split_by_taxid)\n",
    "        if (by_length):\n",
    "            filter_using_water_by_criterion(df, \"contig_length\", split_by_taxid)\n",
    "    return (df)\n",
    "\n",
    "def filter_by_criterion (df, colname, minthreshold, bysample=True):\n",
    "    if bysample:\n",
    "        sums = df.groupby([\"sample\", \"taxid\"])[colname].sum().reset_index()\n",
    "        sums[\"tokeep\"] = sums[colname] >= minthreshold\n",
    "        df = pd.merge(df, sums.drop(columns=colname), how=\"left\")\n",
    "        df = df[df[\"tokeep\"]!=False].drop(columns=\"tokeep\")\n",
    "    else:\n",
    "        df = df[df[colname] >= minthreshold]\n",
    "    return (df)\n",
    "\n",
    "\n",
    "def check_if_in_any_taxid(taxid, taxid_list):\n",
    "    if taxid in taxid_list:\n",
    "        return (taxid)\n",
    "    taxids = ncbi.get_lineage(taxid)\n",
    "    check_in = [i for i, x in enumerate(taxids) if x in taxid_list]\n",
    "    if (len(check_in)==0):\n",
    "        return (np.nan)\n",
    "    return (taxids[check_in[0]])\n",
    "\n",
    "\n",
    "\n",
    "def clean_taxids(df, taxids, root_taxid, taxid_colname=\"taxid\"):\n",
    "    if isinstance(taxids[0], str):\n",
    "        taxids = dict(zip([ncbi.get_name_translator([x])[x][0] for x in taxids], taxids))\n",
    "    else:\n",
    "        taxids = ncbi.get_taxid_translator(taxids)\n",
    "    if isinstance(root_taxid, str):\n",
    "        root_taxid_number = ncbi.get_name_translator([root_taxid])[root_taxid][0]\n",
    "        root_taxid = {root_taxid_number:root_taxid}\n",
    "    else:\n",
    "        root_taxid = ncbi.get_taxid_translator([root_taxid])\n",
    "    df[taxid_colname] = df[taxid_colname].apply(check_if_in_any_taxid, taxid_list=taxids)\n",
    "    df[taxid_colname][df[taxid_colname].isnull()] = list(root_taxid.keys())[0]\n",
    "    taxids.update(root_taxid)\n",
    "    df[\"sci_name\"] = df[taxid_colname].apply(lambda x: taxids[x])\n",
    "    return (df)\n",
    "    \n",
    "\n",
    "def get_summary_table (df, colnames, metric):\n",
    "    df = df.groupby(colnames)[metric].sum().reset_index()\n",
    "    sort_order = colnames+[metric]\n",
    "    sort_order.remove(\"sample\")\n",
    "    return (df.sort_values(by=sort_order, ascending=False))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep hits that are almost identical to a known wolbachia sequence\n",
    "wolbachia_taxid = 952\n",
    "wolbachia_contigs = get_rows_taxid(contig_stats_lca, taxid=wolbachia_taxid, taxid_colname=\"taxid\", identity_qcov_cutoff=identity_qcov_threshold)\n",
    "# Filter contigs that were less abundant or shorter than contigs found in water belonging to the same taxid\n",
    "wolbachia_contigs = use_water_filter(wolbachia_contigs, by_read_count=True, by_length=True)\n",
    "# Filter taxids for which the total length of contigs in a sample was less than min_total_contig_len (default 1000 bp)\n",
    "wolbachia_contigs = filter_by_criterion(wolbachia_contigs, \"contig_length\", minthreshold=min_total_contig_len, bysample=True)\n",
    "# Return a list of species grouped by mosquito species, collection site, sample, and taxid, and sorted by total read count\n",
    "wolbachia_contigs = get_summary_table(wolbachia_contigs, colnames=[\"ska_genus\", \"ska_species\", \"collected_by\", \"sample\"], metric=\"read_prop\")\n",
    "wolbachia_contigs = wolbachia_contigs.assign(taxid=wolbachia_taxid)\n",
    "wolbachia_contigs = wolbachia_contigs.assign(sci_name=ncbi.get_taxid_translator([wolbachia_taxid])[wolbachia_taxid])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep hits that are almost identical to a known viral sequence\n",
    "viral_contigs = get_rows_taxid(contig_stats_lca, taxid=10239, taxid_colname=\"taxid\", identity_qcov_cutoff=identity_qcov_threshold)\n",
    "# Filter contigs that were less abundant or shorter than contigs found in water belonging to the same taxid\n",
    "viral_contigs = use_water_filter(viral_contigs, by_read_count=True, by_length=True, split_by_taxid=True)\n",
    "# Filter taxids for which the total length of contigs in a sample was less than 500bp\n",
    "viral_contigs = filter_by_criterion(viral_contigs, \"contig_length\", minthreshold=500, bysample=True)\n",
    "# Convert taxids to those of interest\n",
    "viral_groups = [\"unclassified Riboviria\", \"Bunyavirales\", \"Orthomyxoviridae\", \"Mononegavirales\", \n",
    "                \"Nodaviridae\", \"Flavivirus\", \"Narnaviridae\", \"Totiviridae\", \"Iflaviridae\", \"dsRNA viruses\"]\n",
    "viral_contigs = clean_taxids(viral_contigs, taxids=viral_groups, root_taxid=10239)\n",
    "# Return a list of species grouped by mosquito species, collection site, sample, and taxid, and sorted by total read count\n",
    "viral_contigs = get_summary_table(viral_contigs, colnames=[\"ska_genus\", \"ska_species\", \"collected_by\", \"sample\", \"taxid\", \"sci_name\"], metric=\"read_prop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep hits that are almost identical to a known metazoan sequence\n",
    "metazoan_contigs = contig_stats_lca[(contig_stats_lca[\"taxon_group\"]==\"Metazoa\") & (contig_stats_lca[\"identity_qcov\"]>=identity_qcov_threshold)]\n",
    "# Filter contigs that were less abundant or shorter than contigs found in water belonging to the same taxid\n",
    "metazoan_contigs = use_water_filter(metazoan_contigs, by_read_count=True, by_length=True, split_by_taxid=True)\n",
    "# Filter taxids for which the total length of contigs in a sample was less than min_total_contig_len (default 1000 bp)\n",
    "metazoan_contigs = filter_by_criterion(metazoan_contigs, \"contig_length\", minthreshold=min_total_contig_len, bysample=True)\n",
    "# Convert taxids to those of interest\n",
    "metazoan_contigs = clean_taxids(metazoan_contigs, taxids=[\"Leporidae\", \"Muroidea\", \"Homo sapiens\", \"Carnivora\", \"Odocoileinae\", \"Bovidae\", \"Neognathae\"], root_taxid=\"Metazoa\")\n",
    "# Return a list of species grouped by mosquito species, collection site, sample, and taxid, and sorted by total read count\n",
    "metazoan_contigs = get_summary_table(metazoan_contigs, colnames=[\"ska_genus\", \"ska_species\", \"collected_by\", \"sample\", \"taxid\", \"sci_name\"], metric=\"read_prop\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep hits that are almost identical to a known eukaryotic sequence\n",
    "eukaryotic_contigs = contig_stats_lca[(contig_stats_lca[\"taxon_group\"]==\"Eukaryota\") & (contig_stats_lca[\"identity_qcov\"]>=identity_qcov_threshold)]\n",
    "# Filter contigs that were less abundant or shorter than contigs found in water belonging to the same taxid\n",
    "eukaryotic_contigs = use_water_filter(eukaryotic_contigs, by_read_count=True, by_length=True, split_by_taxid=True)\n",
    "# Filter taxids for which the total length of contigs in a sample was less than min_total_contig_len (default 1000 bp)\n",
    "eukaryotic_contigs = filter_by_criterion(eukaryotic_contigs, \"contig_length\", minthreshold=min_total_contig_len, bysample=True)\n",
    "# Convert taxids to those of interest\n",
    "eukaryotic_groups = [\"Fungi\", \"Trypanosomatidae\", \"Plasmodium\", \"Stramenopiles\", \"Viridiplantae\", \"Euglenozoa\", \"Alveolata\"]\n",
    "eukaryotic_contigs = clean_taxids(eukaryotic_contigs, taxids=eukaryotic_groups, root_taxid=\"Eukaryota\")\n",
    "# Return a list of species grouped by mosquito species, collection site, sample, and taxid, and sorted by total read count\n",
    "eukaryotic_contigs = get_summary_table(eukaryotic_contigs, colnames=[\"ska_genus\", \"ska_species\", \"collected_by\", \"sample\", \"taxid\", \"sci_name\"], metric=\"read_prop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contigs_df = pd.concat([wolbachia_contigs.assign(group=\"Wolbachia\"), \n",
    "                            viral_contigs.assign(group=\"Virus\"),\n",
    "                            metazoan_contigs.assign(group=\"Metazoa\"), \n",
    "                            eukaryotic_contigs.assign(group=\"Other Eukaryotes\")])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contigs_df.to_csv(\"../../figures/fig3/all_contigs_df.tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
