{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ete3 import NCBITaxa\n",
    "import boto3\n",
    "import tempfile\n",
    "import subprocess\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "ncbi = NCBITaxa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_viral_family_df (row_x):\n",
    "    segments = row_x[\"segments\"]\n",
    "    df_by_sample = pd.DataFrame([x.split(\"|\") for x in segments[list(segments.keys())[0]][\"contigs\"]])\n",
    "    df_by_sample = df_by_sample.assign(sci_name=row_x[\"family\"], taxid=row_x[\"taxid\"])\n",
    "    df_by_sample = df_by_sample.rename(columns={0:\"sample\", 1:\"contig_name\"})\n",
    "    return (df_by_sample)\n",
    "\n",
    "def get_rows_taxid (df, taxid, taxid_colname=\"taxid\", identity_qcov_cutoff=None):\n",
    "    if (not isinstance(df, pd.DataFrame)):\n",
    "        if isinstance(taxid, str):\n",
    "            taxid = ncbi.get_name_translator([taxid])[taxid][0]\n",
    "        return (taxid in ncbi.get_lineage(df))\n",
    "    outdf = df[df[taxid_colname].apply(get_rows_taxid, taxid=taxid)]\n",
    "    if identity_qcov_cutoff is not None:\n",
    "        outdf = outdf[outdf[\"identity_qcov\"]>=identity_qcov_cutoff]\n",
    "    return (outdf)\n",
    "\n",
    "\n",
    "# def filter_by_criterion (df, colname, minthreshold, bysample=True):\n",
    "#     if bysample:\n",
    "#         sums = df.groupby([\"sample\", \"taxid\"])[colname].sum().reset_index()\n",
    "#         sums[\"tokeep\"] = sums[colname] >= minthreshold\n",
    "#         df = pd.merge(df, sums.drop(columns=colname), how=\"left\")\n",
    "#         df = df[df[\"tokeep\"]!=False].drop(columns=\"tokeep\")\n",
    "#     else:\n",
    "#         df = df[df[colname] >= minthreshold]\n",
    "#     return (df)\n",
    "\n",
    "\n",
    "def check_if_in_any_taxid(taxid, taxid_list):\n",
    "    if taxid in taxid_list:\n",
    "        return (taxid)\n",
    "    taxids = ncbi.get_lineage(taxid)\n",
    "    check_in = [i for i, x in enumerate(taxids) if x in taxid_list]\n",
    "    if (len(check_in)==0):\n",
    "        return (np.nan)\n",
    "    return (taxids[check_in[0]])\n",
    "\n",
    "\n",
    "\n",
    "def clean_taxids(df, taxids, root_taxid, taxid_colname=\"taxid\"):\n",
    "    if isinstance(taxids[0], str):\n",
    "        taxids = dict(zip([ncbi.get_name_translator([x])[x][0] for x in taxids], taxids))\n",
    "    else:\n",
    "        taxids = ncbi.get_taxid_translator(taxids)\n",
    "    if isinstance(root_taxid, str):\n",
    "        root_taxid_number = ncbi.get_name_translator([root_taxid])[root_taxid][0]\n",
    "        root_taxid = {root_taxid_number:root_taxid}\n",
    "    else:\n",
    "        root_taxid = ncbi.get_taxid_translator([root_taxid])\n",
    "    df[taxid_colname] = df[taxid_colname].apply(check_if_in_any_taxid, taxid_list=taxids)\n",
    "    df[taxid_colname][df[taxid_colname].isnull()] = list(root_taxid.keys())[0]\n",
    "    taxids.update(root_taxid)\n",
    "    df[\"sci_name\"] = df[taxid_colname].apply(lambda x: taxids[x])\n",
    "    return (df)\n",
    "    \n",
    "    \n",
    "def get_summary_table (df, colnames, metric):\n",
    "    df = df.groupby(colnames)[metric].sum().reset_index()\n",
    "    if not isinstance(metric, list):\n",
    "        metric = [metric]\n",
    "    sort_order = colnames+metric\n",
    "    sort_order.remove(\"sample\")\n",
    "    return (df.sort_values(by=sort_order, ascending=False))\n",
    "\n",
    "def correct_read_count(df, decontam_df, taxid, taxid_colname=\"taxid\"):\n",
    "    if isinstance(taxid, list):\n",
    "        decontam_table = pd.concat([get_rows_taxid(decontam_df, taxid=x, taxid_colname=taxid_colname) for x in taxid])\n",
    "    else:\n",
    "        decontam_table = get_rows_taxid(decontam_df, taxid=taxid, taxid_colname=taxid_colname)\n",
    "    decontam_table = decontam_table.groupby([\"sample\", \"taxid\"])[\"reads\"].sum().reset_index()\n",
    "    outdf = pd.merge(df, decontam_table)\n",
    "    outdf[\"read_prop\"] = outdf[\"reads\"]/outdf[\"read_count\"]*outdf[\"read_prop\"]\n",
    "    outdf = outdf.drop(columns=[\"read_count\", \"reads\"]).rename(columns={\"reads\":\"read_count\"})\n",
    "    return (outdf)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_qcov_threshold = 0.9\n",
    "metadata_cols = [\"ska_genus\", \"ska_species\", \"collected_by\"]\n",
    "numbers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read counts data\n",
    "idseq_data = pd.read_csv(\"../../data/project-mosquito_sample-table.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load metadata\n",
    "metadata = pd.read_csv(\"../../data/metadata/CMS001_CMS002_MergedAnnotations.csv\", header=0)\n",
    "metadata = pd.merge(metadata, idseq_data[[\"sample_name\", \"nonhost_reads\", \"total_reads\"]], left_on=\"NewIDseqName\", right_on=\"sample_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load LCA data\n",
    "contig_stats_lca = pd.read_csv(\"s3://czbiohub-mosquito/contig_quality_concat/contig_stats_lca.tsv\", sep=\"\\t\", header=0)\n",
    "contig_stats_lca = contig_stats_lca.assign(identity_qcov=(contig_stats_lca[\"identity\"]/100*contig_stats_lca[\"align_length\"]/contig_stats_lca[\"contig_length\"]).apply(lambda x: min(x, 1)))\n",
    "numbers[\"total_num_contigs_with_blast_hits\"] = len(contig_stats_lca)\n",
    "contig_stats_lca = contig_stats_lca[~(contig_stats_lca[\"hexapoda\"])]\n",
    "numbers[\"total_nonhexapoda_contigs\"] = len(contig_stats_lca)\n",
    "contig_stats_lca = pd.merge(contig_stats_lca, metadata, how=\"left\", left_on=\"sample\", right_on=\"NewIDseqName\")\n",
    "contig_stats_lca[\"read_prop\"] = contig_stats_lca[\"read_count\"]/contig_stats_lca[\"nonhost_reads\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curated list of known viruses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucy.li/anaconda3/lib/python3.6/site-packages/ete3/ncbi_taxonomy/ncbiquery.py:240: UserWarning: taxid 197514.0 was translated into 2555385\n",
      "  warnings.warn(\"taxid %s was translated into %s\" %(taxid, merged_conversion[taxid]))\n",
      "/Users/lucy.li/anaconda3/lib/python3.6/site-packages/ete3/ncbi_taxonomy/ncbiquery.py:240: UserWarning: taxid 257814.0 was translated into 2608709\n",
      "  warnings.warn(\"taxid %s was translated into %s\" %(taxid, merged_conversion[taxid]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Information about Baltimore classification of virus family groups\n",
    "viral_family_groups = pd.read_csv(\"../../data/virus_family_groups.csv\", header=0)\n",
    "viral_family_groups = viral_family_groups.loc[:, ~viral_family_groups.columns.str.startswith('Unnamed')]\n",
    "# Convert virus json into data frame\n",
    "with open (\"../../data/darkmatter/virus.json\", \"r\") as f:\n",
    "    viral_json = pd.DataFrame(json.load(f)).T\n",
    "viral_contigs = pd.concat(viral_json.apply(get_viral_family_df, axis=1).tolist())\n",
    "numbers[\"num_viral_contigs\"] = len(viral_contigs)\n",
    "# Add read proportions columns\n",
    "viral_contig_stats = get_rows_taxid(contig_stats_lca[[\"sample\", \"read_prop\", \"taxid\", \"contig_name\"]], taxid=10239, taxid_colname=\"taxid\").drop(columns=\"taxid\")\n",
    "viral_contigs = pd.merge(viral_contigs, viral_contig_stats, how=\"left\", on=[\"sample\", \"contig_name\"]).groupby([\"sample\", \"sci_name\", \"taxid\"])[\"read_prop\"].sum().reset_index()\n",
    "print (\"taxid\" in (viral_contigs.columns))\n",
    "# Add metadata information\n",
    "viral_contigs = pd.merge(viral_contigs, contig_stats_lca[[\"sample\"]+metadata_cols].groupby([\"sample\"]).first().reset_index(), how=\"left\")\n",
    "# Add baltimore group information about the viruses\n",
    "viral_contigs = pd.merge(viral_contigs, viral_family_groups, left_on=\"sci_name\", right_on=\"family\", how=\"left\").drop(columns=\"family\")\n",
    "# For viruses belonging to taxid 2607735 (Guadeloupe mosquito virus), change the family denoted in the sci_name column\n",
    "# from \"Virus\" to \"Guadeloupe mosquito virus\", and change Baltimore group and Genome descriptions to \"Unknown\"\n",
    "viral_contigs.loc[viral_contigs[\"baltimore_group\"].isnull(), \"sci_name\"] = \"Guadeloupe mosquito virus\"\n",
    "viral_contigs.loc[viral_contigs[\"baltimore_group\"].isnull(), \"genome_description\"] = \"Unknown\"\n",
    "viral_contigs.loc[viral_contigs[\"baltimore_group\"].isnull(), \"baltimore_group\"] = \"Unknown\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curate lists of non-viral contigs with high-confidence hits to NCBI records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load decontam data\n",
    "true_reads = pd.read_csv(\"s3://czbiohub-mosquito/contig_quality_concat/decontam_sample_read_counts.tsv\", sep=\"\\t\", header=0)\n",
    "contam_reads = pd.read_csv(\"s3://czbiohub-mosquito/contig_quality_concat/sample_contamination.tsv\", sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduct from the nonhost reads per sample the number of reads that were removed due to suspected contamination\n",
    "contig_stats_lca[\"nonhost_reads\"] = pd.merge(contig_stats_lca, contam_reads.groupby(\"sample\")[\"reads\"].sum().reset_index(), how=\"left\").apply(lambda x: x[\"nonhost_reads\"]-x[\"reads\"], axis=1)\n",
    "contig_stats_lca[\"read_prop\"] = contig_stats_lca[\"read_count\"]/contig_stats_lca[\"nonhost_reads\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucy.li/anaconda3/lib/python3.6/site-packages/ete3/ncbi_taxonomy/ncbiquery.py:240: UserWarning: taxid 197514.0 was translated into 2555385\n",
      "  warnings.warn(\"taxid %s was translated into %s\" %(taxid, merged_conversion[taxid]))\n",
      "/Users/lucy.li/anaconda3/lib/python3.6/site-packages/ete3/ncbi_taxonomy/ncbiquery.py:240: UserWarning: taxid 257814.0 was translated into 2608709\n",
      "  warnings.warn(\"taxid %s was translated into %s\" %(taxid, merged_conversion[taxid]))\n",
      "/Users/lucy.li/anaconda3/lib/python3.6/site-packages/ete3/ncbi_taxonomy/ncbiquery.py:240: UserWarning: taxid 257814 was translated into 2608709\n",
      "  warnings.warn(\"taxid %s was translated into %s\" %(taxid, merged_conversion[taxid]))\n"
     ]
    }
   ],
   "source": [
    "# Only keep hits that are almost identical to a known wolbachia sequence\n",
    "wolbachia_taxid = 952\n",
    "wolbachia_contigs = get_rows_taxid(contig_stats_lca, taxid=wolbachia_taxid, taxid_colname=\"taxid\", identity_qcov_cutoff=identity_qcov_threshold)\n",
    "# Only keep wolbachia groups that were not removed by the decontamination step\n",
    "wolbachia_contigs = wolbachia_contigs[wolbachia_contigs[\"taxid\"].isin(true_reads[\"taxid\"])]\n",
    "numbers[\"total_wolbachia_contigs\"] = len(wolbachia_contigs)\n",
    "# Return a list of species grouped by mosquito species, collection site, sample, and taxid, and sorted by total read count\n",
    "wolbachia_contigs = get_summary_table(wolbachia_contigs, colnames=[\"ska_genus\", \"ska_species\", \"collected_by\", \"sample\", \"taxid\"], metric=[\"read_count\", \"read_prop\"])\n",
    "# Correct read counts after decontamination\n",
    "wolbachia_contigs = correct_read_count(wolbachia_contigs, true_reads, wolbachia_taxid, \"taxid\")\n",
    "#wolbachia_contigs = wolbachia_contigs.assign(taxid=wolbachia_taxid)\n",
    "# Create sci_name column to denote that that this table contains Wolbachia samples\n",
    "wolbachia_contigs = wolbachia_contigs.assign(sci_name=ncbi.get_taxid_translator([wolbachia_taxid])[wolbachia_taxid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucy.li/anaconda3/lib/python3.6/site-packages/ete3/ncbi_taxonomy/ncbiquery.py:240: UserWarning: taxid 257814 was translated into 2608709\n",
      "  warnings.warn(\"taxid %s was translated into %s\" %(taxid, merged_conversion[taxid]))\n"
     ]
    }
   ],
   "source": [
    "# Only keep hits that are almost identical to a known metazoan sequence\n",
    "metazoan_contigs = contig_stats_lca[(contig_stats_lca[\"taxon_group\"]==\"Metazoa\") & (contig_stats_lca[\"identity_qcov\"]>=identity_qcov_threshold)]\n",
    "# Only keep metazoan groups that were not removed by the decontamination step\n",
    "metazoan_contigs = metazoan_contigs[metazoan_contigs[\"taxid\"].isin(true_reads[\"taxid\"])]\n",
    "# Convert taxids to those of interest\n",
    "#metazoan_contigs = clean_taxids(metazoan_contigs, taxids=[\"Leporidae\", \"Muroidea\", \"Homo sapiens\", \"Carnivora\", \"Odocoileinae\", \"Bovidae\", \"Neognathae\"], root_taxid=\"Metazoa\")\n",
    "metazoan_contigs = metazoan_contigs.assign(sci_name=metazoan_contigs[\"taxid\"].apply(lambda x: ncbi.get_taxid_translator([x])[x]))\n",
    "numbers[\"total_metazoan_contigs\"] = len(metazoan_contigs)\n",
    "# Return a list of species grouped by mosquito species, collection site, sample, and taxid, and sorted by total read count\n",
    "metazoan_contigs = get_summary_table(metazoan_contigs, colnames=metadata_cols+[\"sample\", \"taxid\", \"sci_name\"], metric=[\"read_count\", \"read_prop\"])\n",
    "# Correct read counts after decontamination\n",
    "metazoan_contigs = correct_read_count(metazoan_contigs, true_reads, taxid=\"Metazoa\", taxid_colname=\"taxid\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucy.li/anaconda3/lib/python3.6/site-packages/ete3/ncbi_taxonomy/ncbiquery.py:240: UserWarning: taxid 257814 was translated into 2608709\n",
      "  warnings.warn(\"taxid %s was translated into %s\" %(taxid, merged_conversion[taxid]))\n"
     ]
    }
   ],
   "source": [
    "# Only keep hits that are almost identical to a known eukaryote sequence\n",
    "eukaryotic_taxids = [\"Fungi\", \"Trypanosomatidae\", \"Plasmodium\", \"Stramenopiles\", \"Viridiplantae\", \"Euglenozoa\", \"Alveolata\"]\n",
    "eukaryotic_contigs = contig_stats_lca[(contig_stats_lca[\"taxon_group\"]==\"Eukaryota\") & (contig_stats_lca[\"identity_qcov\"]>=identity_qcov_threshold)]\n",
    "# Only keep eukaryotic groups that were not removed by the decontamination step\n",
    "eukaryotic_contigs = eukaryotic_contigs[eukaryotic_contigs[\"taxid\"].isin(true_reads[\"taxid\"])]\n",
    "# Convert taxids to those of interest\n",
    "#eukaryotic_contigs = clean_taxids(eukaryotic_contigs, taxids=eukaryotic_taxids, root_taxid=\"Eukaryota\")\n",
    "eukaryotic_contigs = eukaryotic_contigs.assign(sci_name=eukaryotic_contigs[\"taxid\"].apply(lambda x: ncbi.get_taxid_translator([x])[x]))\n",
    "numbers[\"total_eukaryotic_contigs\"] = len(eukaryotic_contigs)\n",
    "# Return a list of species grouped by mosquito species, collection site, sample, and taxid, and sorted by total read count\n",
    "eukaryotic_contigs = get_summary_table(eukaryotic_contigs, colnames=metadata_cols+[\"sample\", \"taxid\", \"sci_name\"], metric=[\"read_count\", \"read_prop\"])\n",
    "# Correct read counts after decontamination\n",
    "eukaryotic_contigs = correct_read_count(eukaryotic_contigs, true_reads, taxid=eukaryotic_taxids, taxid_colname=\"taxid\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucy.li/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "all_contigs_df = pd.concat([wolbachia_contigs.assign(group=\"Wolbachia\"), \n",
    "                            viral_contigs.assign(group=\"Virus\"),\n",
    "                            metazoan_contigs.assign(group=\"Metazoa\"), \n",
    "                            eukaryotic_contigs.assign(group=\"Other Eukaryotes\")])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contigs_df.to_csv(\"../../figures/fig3/all_contigs_df.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
