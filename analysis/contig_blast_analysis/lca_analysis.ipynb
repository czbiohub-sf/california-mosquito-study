{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from ete3 import NCBITaxa\n",
    "import subprocess\n",
    "import itertools\n",
    "import os\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from lca_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "client = boto3.client('s3')\n",
    "bucket_name = \"czbiohub-mosquito\"\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "contig_folders = [x[\"Prefix\"] for x in client.list_objects(Bucket=bucket_name, Prefix=\"contigs/\", Delimiter=\"/\")[\"CommonPrefixes\"]]\n",
    "contig_quality_folders = [x[\"Prefix\"] for x in client.list_objects(Bucket=bucket_name, Prefix=\"contig_quality/\", Delimiter=\"/\")[\"CommonPrefixes\"] if \"Mos\" not in x[\"Prefix\"]]\n",
    "\n",
    "ncores = os.cpu_count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi = NCBITaxa()\n",
    "# ncbi.update_taxonomy_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_count_files = [client.list_objects(Bucket=bucket_name, Prefix=x+\"Mos/bowtie_csp_counts_1000.txt\") \\\n",
    "                   if \"Water\" not in x \\\n",
    "                    else client.list_objects(Bucket=bucket_name, Prefix=x+\"bowtie_csp_counts_1000.txt\") \\\n",
    "                    for x in contig_quality_folders]\n",
    "read_count_files = [\"s3://\"+bucket_name+\"/\"+x[\"Prefix\"] for x in read_count_files if \"Contents\" in x.keys()]\n",
    "read_counts_csp_1000 = pd.concat([pd.read_csv(x, sep=\"\\t\", header=None, names=[\"query\", \"read_count\"]).\\\n",
    "                                  assign(sample=os.path.split(os.path.split(x)[0])[1]) for x in read_count_files])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5585511851875872"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(read_counts_csp_1000[\"read_count\"]>2)/len(read_counts_csp_1000.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340346.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143869.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>72956.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44114.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29082.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21093.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15529.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12045.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9854.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>51271.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15792.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12588.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2050.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1\n",
       "0        0.0      0.0\n",
       "1        0.0      1.0\n",
       "2   340346.0      2.0\n",
       "3        0.0      3.0\n",
       "4   143869.0      4.0\n",
       "5        0.0      5.0\n",
       "6    72956.0      6.0\n",
       "7        0.0      7.0\n",
       "8    44114.0      8.0\n",
       "9        0.0      9.0\n",
       "10   29082.0     10.0\n",
       "11       0.0     11.0\n",
       "12   21093.0     12.0\n",
       "13       0.0     13.0\n",
       "14   15529.0     14.0\n",
       "15       0.0     15.0\n",
       "16   12045.0     16.0\n",
       "17       0.0     17.0\n",
       "18    9854.0     18.0\n",
       "19       0.0     19.0\n",
       "20   51271.0     20.0\n",
       "21   15792.0     50.0\n",
       "22   12588.0    100.0\n",
       "23    2050.0   1000.0\n",
       "24       NaN  10000.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.histogram(read_counts_csp_1000[\"read_count\"], \n",
    "                          bins=list(range(21))+[50, 100, 1000, 10000])).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_contigs_by_read_count = read_counts_csp_1000[read_counts_csp_1000[\"read_count\"]>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-81e603c840d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiltered_contigs_by_read_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfiltered_contigs_by_read_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NODE_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfiltered_contigs_by_read_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sample\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CMS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/tools/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m   1468\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "filtered_contigs_by_read_count[filtered_contigs_by_read_count[\"query\"].str.startswith(\"NODE_\") and filtered_contigs_by_read_count[\"sample\"].str.startswith(\"CMS\")]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lca_analysis (input_file_name, output_dir, bucket_name, ident_cutoff, align_cutoff, bitscore_cutoff, \\\n",
    "                      blast_type, default=False, ncores=8):\n",
    "    # First list the folders (there is a limit of 1000 files output by AWS by default)\n",
    "    list_of_folders = [client.list_objects(Bucket=bucket_name, Prefix=x[\"Prefix\"]+input_file_name) \\\n",
    "                       for x in client.list_objects(Bucket=bucket_name, Prefix=\"contigs/\", Delimiter=\"/\")[\"CommonPrefixes\"]]\n",
    "    list_of_folders = [\"s3://\"+bucket_name+\"/\"+x[\"Prefix\"] for x in list_of_folders if \"Contents\" in x.keys()]\n",
    "    filenames = pd.DataFrame(list_of_folders, columns=[\"blast_\"+blast_type])\n",
    "    output_string = output_dir\n",
    "    if not default:\n",
    "        output_string += \"/ident\"+str(ident_cutoff)+\"align\"+str(align_cutoff)+\"bitscore\"+str(bitscore_cutoff)\n",
    "    filenames = filenames.assign(filtered_blast=filenames[\"blast_\"+blast_type].str.replace(\"contigs\", output_string).str.replace(\".m9\", \"_filtered.m9\"))\n",
    "    filenames = filenames.assign(lca=filenames[\"filtered_blast\"].str.replace(\"blast_\"+blast_type, \"lca_\"+blast_type).str.replace(\"_filtered\", \"\"))\n",
    "    filenames = filenames.assign(reads=filenames[\"lca\"].str.replace(\"lca_\"+blast_type+\".m9\", \"bowtie_csp_counts_1000.txt\"))\n",
    "    filenames.loc[~filenames[\"reads\"].str.contains(\"ater\"), \"reads\"] = filenames.loc[~filenames[\"reads\"].str.contains(\"ater\"), \"reads\"].str.replace(\"bowtie\", \"Mos/bowtie\")\n",
    "    commands = filenames.apply(lambda x: \"python lca_analysis.py\"+\\\n",
    "                               \" --blast_type \"+blast_type+\\\n",
    "                               \" --fpath \"+x.iloc[0]+\\\n",
    "                               \" --filtered_blast_path \"+x.iloc[1]+\\\n",
    "                               \" --outpath \"+x.iloc[2]+\\\n",
    "                               \" --read_count_path \"+x.iloc[3]+\\\n",
    "                               \" --ident_cutoff \"+str(ident_cutoff)+\\\n",
    "                               \" --align_len_cutoff \"+str(align_cutoff)+\\\n",
    "                               \" --bitscore_cutoff \"+str(bitscore_cutoff), axis=1)\n",
    "    print (commands)\n",
    "    commands_csv_filename = \"lca_\"+blast_type+\"_commands\"\n",
    "    if not default:\n",
    "        commands_csv_filename += \"_ident\"+str(ident_cutoff)+\"align\"+str(align_cutoff)+\"bitscore\"+str(bitscore_cutoff)\n",
    "    commands.to_csv(commands_csv_filename, index=False)\n",
    "    if (len(filenames) < ncores):\n",
    "        ncores = len(filenames)\n",
    "    command_str = \"parallel -a \"+commands_csv_filename+\" -j \"+str(ncores)\n",
    "    print (command_str)\n",
    "#     process = subprocess.Popen(command_str.split(), stdout=subprocess.PIPE)\n",
    "#     output, error = process.communicate()\n",
    "#     return (output, error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_blast_lca (lca_file_name, blast_file_name, outfile, sample_name, blast_type, output_file_name=None):\n",
    "    lca_data = pd.read_csv(lca_file_name, sep=\"\\t\", header=0)\n",
    "    blast_data = pd.read_csv(blast_file_name, sep=\"\\t\", header=0)\n",
    "    blast_data_grouped = blast_data.groupby([\"query\"], as_index=False).\\\n",
    "    apply(lambda x: x[x[\"bitscore\"]==max(x[\"bitscore\"])].head(n=1))\n",
    "    blast_data_grouped = blast_data_grouped[['query', 'identity', 'align_length', 'mismatches', 'gaps',\n",
    "                                             'qstart', 'qend', 'sstart', 'send', 'bitscore']]\n",
    "#     agg({'identity':[\"max\"], 'align_length':[\"max\"], 'mismatches':[\"max\"], 'gaps':[\"max\"],\n",
    "#          'qstart':[\"min\"], 'qend':[\"max\"], 'sstart':[\"min\"], 'send':[\"max\"],\n",
    "#          'bitscore':[\"max\"]})\n",
    "    blast_data_grouped.columns = blast_data_grouped.columns.get_level_values(0)\n",
    "    grouped_df = pd.merge(blast_data_grouped, lca_data, how=\"left\", on=\"query\")\n",
    "    grouped_df.insert(1, \"blast_type\", value=blast_type)\n",
    "    grouped_df.insert(2, \"sample\", value=sample_name)\n",
    "    df_to_s3(grouped_df, outfile)\n",
    "    outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Produce a dataframe from every combination of values\n",
    "## From: https://pandas.pydata.org/pandas-docs/stable/user_guide/cookbook.html\n",
    "##\n",
    "def expand_grid(data_dict):\n",
    "    rows = itertools.product(*data_dict.values())\n",
    "    return pd.DataFrame.from_records(rows, columns=data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = pd.concat([\n",
    "    expand_grid({\n",
    "        \"ident_cutoff\":[x*0.1 for x in range(0, 10)], \\\n",
    "        \"align_cutoff\":[x*0.1 for x in range(0, 10)], \\\n",
    "        \"bitscore_cutoff\":[0]\n",
    "    }),\n",
    "    expand_grid({\"ident_cutoff\":[0], \"align_cutoff\":[0], \"bitscore_cutoff\":[x*0.1 for x in range(0, 10)]})\n",
    "], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nt hits\n",
    "The nt hits of contigs from each sample are filtered with ident_cutoff=0.9 and align_len_cutoff=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      python lca_analysis.py --blast_type nt --fpath...\n",
      "1      python lca_analysis.py --blast_type nt --fpath...\n",
      "2      python lca_analysis.py --blast_type nt --fpath...\n",
      "3      python lca_analysis.py --blast_type nt --fpath...\n",
      "4      python lca_analysis.py --blast_type nt --fpath...\n",
      "5      python lca_analysis.py --blast_type nt --fpath...\n",
      "6      python lca_analysis.py --blast_type nt --fpath...\n",
      "7      python lca_analysis.py --blast_type nt --fpath...\n",
      "8      python lca_analysis.py --blast_type nt --fpath...\n",
      "9      python lca_analysis.py --blast_type nt --fpath...\n",
      "10     python lca_analysis.py --blast_type nt --fpath...\n",
      "11     python lca_analysis.py --blast_type nt --fpath...\n",
      "12     python lca_analysis.py --blast_type nt --fpath...\n",
      "13     python lca_analysis.py --blast_type nt --fpath...\n",
      "14     python lca_analysis.py --blast_type nt --fpath...\n",
      "15     python lca_analysis.py --blast_type nt --fpath...\n",
      "16     python lca_analysis.py --blast_type nt --fpath...\n",
      "17     python lca_analysis.py --blast_type nt --fpath...\n",
      "18     python lca_analysis.py --blast_type nt --fpath...\n",
      "19     python lca_analysis.py --blast_type nt --fpath...\n",
      "20     python lca_analysis.py --blast_type nt --fpath...\n",
      "21     python lca_analysis.py --blast_type nt --fpath...\n",
      "22     python lca_analysis.py --blast_type nt --fpath...\n",
      "23     python lca_analysis.py --blast_type nt --fpath...\n",
      "24     python lca_analysis.py --blast_type nt --fpath...\n",
      "25     python lca_analysis.py --blast_type nt --fpath...\n",
      "26     python lca_analysis.py --blast_type nt --fpath...\n",
      "27     python lca_analysis.py --blast_type nt --fpath...\n",
      "28     python lca_analysis.py --blast_type nt --fpath...\n",
      "29     python lca_analysis.py --blast_type nt --fpath...\n",
      "                             ...                        \n",
      "125    python lca_analysis.py --blast_type nt --fpath...\n",
      "126    python lca_analysis.py --blast_type nt --fpath...\n",
      "127    python lca_analysis.py --blast_type nt --fpath...\n",
      "128    python lca_analysis.py --blast_type nt --fpath...\n",
      "129    python lca_analysis.py --blast_type nt --fpath...\n",
      "130    python lca_analysis.py --blast_type nt --fpath...\n",
      "131    python lca_analysis.py --blast_type nt --fpath...\n",
      "132    python lca_analysis.py --blast_type nt --fpath...\n",
      "133    python lca_analysis.py --blast_type nt --fpath...\n",
      "134    python lca_analysis.py --blast_type nt --fpath...\n",
      "135    python lca_analysis.py --blast_type nt --fpath...\n",
      "136    python lca_analysis.py --blast_type nt --fpath...\n",
      "137    python lca_analysis.py --blast_type nt --fpath...\n",
      "138    python lca_analysis.py --blast_type nt --fpath...\n",
      "139    python lca_analysis.py --blast_type nt --fpath...\n",
      "140    python lca_analysis.py --blast_type nt --fpath...\n",
      "141    python lca_analysis.py --blast_type nt --fpath...\n",
      "142    python lca_analysis.py --blast_type nt --fpath...\n",
      "143    python lca_analysis.py --blast_type nt --fpath...\n",
      "144    python lca_analysis.py --blast_type nt --fpath...\n",
      "145    python lca_analysis.py --blast_type nt --fpath...\n",
      "146    python lca_analysis.py --blast_type nt --fpath...\n",
      "147    python lca_analysis.py --blast_type nt --fpath...\n",
      "148    python lca_analysis.py --blast_type nt --fpath...\n",
      "149    python lca_analysis.py --blast_type nt --fpath...\n",
      "150    python lca_analysis.py --blast_type nt --fpath...\n",
      "151    python lca_analysis.py --blast_type nt --fpath...\n",
      "152    python lca_analysis.py --blast_type nt --fpath...\n",
      "153    python lca_analysis.py --blast_type nt --fpath...\n",
      "154    python lca_analysis.py --blast_type nt --fpath...\n",
      "Length: 155, dtype: object\n",
      "parallel -a lca_nt_commands -j 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/tools/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "run_lca_analysis(input_file_name=\"blast_nt.m9\", output_dir=\"contig_quality\", \\\n",
    "                 bucket_name=bucket_name,\\\n",
    "                 ident_cutoff=0.9, align_cutoff=0.9, bitscore_cutoff=0, \\\n",
    "                 blast_type=\"nt\", default=True, ncores=ncores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity analysis using different combinations of cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_nt_paths = [\"s3://\"+bucket_name+\"/\"+x[\"Prefix\"]+\"lca_nt.m9\" \\\n",
    " for x in client.list_objects(Bucket=bucket_name, Prefix=\"contig_quality/\", Delimiter=\"/\")[\"CommonPrefixes\"] if \"Mos\" not in x[\"Prefix\"]]\n",
    "blast_nt_paths = [x.replace(\"lca_nt\", \"blast_nt_filtered\") for x in lca_nt_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "sample_name = os.path.basename(os.path.dirname(lca_nt_paths[i]))\n",
    "outfile = lca_nt_paths[i].replace(\"lca_nt\", \"blast_lca_nt_filtered_test\")\n",
    "combine_blast_lca (lca_nt_paths[i], blast_nt_paths[i], outfile, sample_name, \"nt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: CMS001_water1_S11\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lca_nt_paths)):\n",
    "    sample_name = os.path.basename(os.path.dirname(lca_nt_paths[i]))\n",
    "    outfile = lca_nt_paths[i].replace(\"lca_nt\", \"blast_lca_nt_filtered\")\n",
    "    try:\n",
    "        combine_blast_lca (lca_nt_paths[i], blast_nt_paths[i], outfile, sample_name, \"nt\")\n",
    "    except:\n",
    "        print (\"error: \"+sample_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations.apply(lambda x: \\\n",
    "                   run_lca_analysis(input_file_name=\"blast_nt.m9\", output_dir=\"contig_quality_sensitivity\", \\\n",
    "                                    ident_cutoff=x[\"ident_cutoff\"], align_cutoff=x[\"align_cutoff\"], \\\n",
    "                                    bitscore_cutoff=x[\"bitscore_cutoff\"], \\\n",
    "                                    blast_type=\"nt\", default=False, ncores=ncores), \\\n",
    "                   axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nr hits\n",
    "The nr hits of contigs from each sample are filtered with ident_cutoff=0.9 and align_len_cutoff=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 ls s3://czbiohub-mosquito/plast/ | grep '.m8' | awk 'NF>1{print $NF}' | parallel -j 72 python create_blast_nr.py --fpath s3://czbiohub-mosquito/plast/{}\n",
    "aws s3 ls s3://lucymli/skeeters/blast_nr/ | grep 'CMS00' | awk 'NF>1{print $NF}' | parallel aws s3 sync s3://lucymli/skeeters/blast_nr/{} blast_nr_output/{}\n",
    "head -n 1 $(find blast_nr_output -type f -name '*.m8' | head -n 1) > header_line \n",
    "for x in `ls blast_nr_output`; do \n",
    "    mkdir -p blast_nr_output_full/$x\n",
    "    head -n 1 $(find blast_nr_output -type f -name '*.m8' | head -n 1) > blast_nr_output_full/$x/blast_nr.m9\n",
    "    ls -d $(find blast_nr_output/$x -type f) | xargs -0 -I file cat file > blast_nr_output_full/$x/blast_nr.m9\n",
    "done\n",
    "ls blast_nr_output_full | parallel aws s3 cp blast_nr_output_full/{}/blast_nr.m9 s3://czbiohub-mosquito/contigs/{}/blast_nr.m9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      python lca_analysis.py --blast_type nr --fpath...\n",
      "1      python lca_analysis.py --blast_type nr --fpath...\n",
      "2      python lca_analysis.py --blast_type nr --fpath...\n",
      "3      python lca_analysis.py --blast_type nr --fpath...\n",
      "4      python lca_analysis.py --blast_type nr --fpath...\n",
      "5      python lca_analysis.py --blast_type nr --fpath...\n",
      "6      python lca_analysis.py --blast_type nr --fpath...\n",
      "7      python lca_analysis.py --blast_type nr --fpath...\n",
      "8      python lca_analysis.py --blast_type nr --fpath...\n",
      "9      python lca_analysis.py --blast_type nr --fpath...\n",
      "10     python lca_analysis.py --blast_type nr --fpath...\n",
      "11     python lca_analysis.py --blast_type nr --fpath...\n",
      "12     python lca_analysis.py --blast_type nr --fpath...\n",
      "13     python lca_analysis.py --blast_type nr --fpath...\n",
      "14     python lca_analysis.py --blast_type nr --fpath...\n",
      "15     python lca_analysis.py --blast_type nr --fpath...\n",
      "16     python lca_analysis.py --blast_type nr --fpath...\n",
      "17     python lca_analysis.py --blast_type nr --fpath...\n",
      "18     python lca_analysis.py --blast_type nr --fpath...\n",
      "19     python lca_analysis.py --blast_type nr --fpath...\n",
      "20     python lca_analysis.py --blast_type nr --fpath...\n",
      "21     python lca_analysis.py --blast_type nr --fpath...\n",
      "22     python lca_analysis.py --blast_type nr --fpath...\n",
      "23     python lca_analysis.py --blast_type nr --fpath...\n",
      "24     python lca_analysis.py --blast_type nr --fpath...\n",
      "25     python lca_analysis.py --blast_type nr --fpath...\n",
      "26     python lca_analysis.py --blast_type nr --fpath...\n",
      "27     python lca_analysis.py --blast_type nr --fpath...\n",
      "28     python lca_analysis.py --blast_type nr --fpath...\n",
      "29     python lca_analysis.py --blast_type nr --fpath...\n",
      "                             ...                        \n",
      "125    python lca_analysis.py --blast_type nr --fpath...\n",
      "126    python lca_analysis.py --blast_type nr --fpath...\n",
      "127    python lca_analysis.py --blast_type nr --fpath...\n",
      "128    python lca_analysis.py --blast_type nr --fpath...\n",
      "129    python lca_analysis.py --blast_type nr --fpath...\n",
      "130    python lca_analysis.py --blast_type nr --fpath...\n",
      "131    python lca_analysis.py --blast_type nr --fpath...\n",
      "132    python lca_analysis.py --blast_type nr --fpath...\n",
      "133    python lca_analysis.py --blast_type nr --fpath...\n",
      "134    python lca_analysis.py --blast_type nr --fpath...\n",
      "135    python lca_analysis.py --blast_type nr --fpath...\n",
      "136    python lca_analysis.py --blast_type nr --fpath...\n",
      "137    python lca_analysis.py --blast_type nr --fpath...\n",
      "138    python lca_analysis.py --blast_type nr --fpath...\n",
      "139    python lca_analysis.py --blast_type nr --fpath...\n",
      "140    python lca_analysis.py --blast_type nr --fpath...\n",
      "141    python lca_analysis.py --blast_type nr --fpath...\n",
      "142    python lca_analysis.py --blast_type nr --fpath...\n",
      "143    python lca_analysis.py --blast_type nr --fpath...\n",
      "144    python lca_analysis.py --blast_type nr --fpath...\n",
      "145    python lca_analysis.py --blast_type nr --fpath...\n",
      "146    python lca_analysis.py --blast_type nr --fpath...\n",
      "147    python lca_analysis.py --blast_type nr --fpath...\n",
      "148    python lca_analysis.py --blast_type nr --fpath...\n",
      "149    python lca_analysis.py --blast_type nr --fpath...\n",
      "150    python lca_analysis.py --blast_type nr --fpath...\n",
      "151    python lca_analysis.py --blast_type nr --fpath...\n",
      "152    python lca_analysis.py --blast_type nr --fpath...\n",
      "153    python lca_analysis.py --blast_type nr --fpath...\n",
      "154    python lca_analysis.py --blast_type nr --fpath...\n",
      "Length: 155, dtype: object\n",
      "parallel -a lca_nr_commands -j 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/tools/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "run_lca_analysis(input_file_name=\"blast_nr.m9\", output_dir=\"contig_quality\", \\\n",
    "                 bucket_name=bucket_name,\\\n",
    "                 ident_cutoff=0.9, align_cutoff=0.9, bitscore_cutoff=0, \\\n",
    "                 blast_type=\"nr\", default=True, ncores=ncores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_nr_paths = [\"s3://\"+bucket_name+\"/\"+x[\"Prefix\"]+\"lca_nr.m9\" \\\n",
    " for x in client.list_objects(Bucket=bucket_name, Prefix=\"contig_quality/\", Delimiter=\"/\")[\"CommonPrefixes\"] if \"Mos\" not in x[\"Prefix\"]]\n",
    "blast_nr_paths = [x.replace(\"lca_nr\", \"blast_nr_filtered\") for x in lca_nr_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lca_nr_paths)):\n",
    "    sample_name = os.path.basename(os.path.dirname(lca_nr_paths[i]))\n",
    "    outfile = lca_nr_paths[i].replace(\"lca_nr\", \"blast_lca_nr_filtered\")\n",
    "    try:\n",
    "        combine_blast_lca (lca_nr_paths[i], blast_nr_paths[i], outfile, sample_name, \"nr\")\n",
    "    except:\n",
    "        print (\"error: \"+sample_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subset nr hits (NO NEED TO RUN NOW THAT NR RESULTS FROM PLAST ARE AVAILABLE)\n",
    "The subset nr hits of contigs from each sample are filtered with ident_cutoff=0.9 and align_len_cutoff=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_lca_analysis(input_file_name=\"blast_subset_nr.m9\", output_dir=\"contig_quality\", \\\n",
    "                 bucket_name=bucket_name,\\\n",
    "                 ident_cutoff=0.9, align_cutoff=0.9, bitscore_cutoff=0, \\\n",
    "                 blast_type=\"nr\", default=True, ncores=ncores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations.apply(lambda x: \\\n",
    "                   run_lca_analysis(input_file_name=\"blast_subset_nr.m9\", output_dir=\"contig_quality_sensitivity\", \\\n",
    "                                    ident_cutoff=x[\"ident_cutoff\"], align_cutoff=x[\"align_cutoff\"], \\\n",
    "                                    bitscore_cutoff=x[\"bitscore_cutoff\"], \\\n",
    "                                    blast_type=\"nr\", default=False, ncores=ncores), \\\n",
    "                   axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_file = pd.read_csv(\"s3://czbiohub-mosquito/contigs/CMS001_003_Ra_S2/blast_nt.m9\", header=None, sep=\"\\t\", comment=\"#\")\n",
    "blast_lca_file = pd.read_csv(\"s3://czbiohub-mosquito/contig_quality/CMS001_003_Ra_S2/blast_lca_nt_filtered.m9\", header=0, sep=\"\\t\", comment=\"#\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[contig_file[contig_file[0]==x][12].isin(ncbi.get_descendant_taxa(\"7157\")).any()\\\n",
    " for x in blast_lca_file[blast_lca_file[\"taxid\"]==33213][\"query\"]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_lca_file[blast_lca_file[\"taxid\"]==33213].iloc[6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_file[contig_file[0]==\"NODE_5053_length_360_cov_0.664311\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = contig_file\n",
    "db=\"nucleotide\"\n",
    "return_taxid_only=True\n",
    "ident_cutoff=0.9\n",
    "align_len_cutoff=0.9\n",
    "bitscore_cutoff=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(contig_file[0][0].split(\"_\")[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_nr = pd.read_csv(\"s3://czbiohub-mosquito/contigs/CMS001_026_Ra_S18/blast_nr.m9\", header=None, sep=\"\\t\", comment=\"#\")\n",
    "blast_nt = pd.read_csv(\"s3://czbiohub-mosquito/contigs/CMS001_026_Ra_S18/blast_nt.m9\", header=None, sep=\"\\t\", comment=\"#\")\n",
    "read_counts = pd.read_csv(\"s3://czbiohub-mosquito/contig_quality/CMS001_026_Ra_S18/bowtie_csp_counts_1000.txt\", header=None, sep=\"\\t\", comment=\"#\")\n",
    "#blast_lca_file = pd.read_csv(\"s3://czbiohub-mosquito/contig_quality/CMS001_026_Ra_S18/blast_lca_nr_filtered.m9\", header=0, sep=\"\\t\", comment=\"#\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_counts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_acc = [x.split(\"|\")[-2] for x in blast_nr[1].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxids = [x[\"TaxId\"] for x in list(Entrez.parse(Entrez.esummary(db=\"protein\", id=','.join(unique_acc[:400]), retmode=\"xml\")))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[6960 in ncbi.get_lineage(x) for x in taxids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
