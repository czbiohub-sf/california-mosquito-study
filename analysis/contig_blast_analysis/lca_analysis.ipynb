{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from ete3 import NCBITaxa\n",
    "import subprocess\n",
    "import itertools\n",
    "import os\n",
    "import s3fs\n",
    "import numpy as np\n",
    "from lca_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "client = boto3.client('s3')\n",
    "bucket_name = \"czbiohub-mosquito\"\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "contig_folders = [x[\"Prefix\"] for x in client.list_objects(Bucket=bucket_name, Prefix=\"contigs/\", Delimiter=\"/\")[\"CommonPrefixes\"]]\n",
    "contig_quality_folders = [x[\"Prefix\"] for x in client.list_objects(Bucket=bucket_name, Prefix=\"contig_quality/\", Delimiter=\"/\")[\"CommonPrefixes\"] if \"Mos\" not in x[\"Prefix\"]]\n",
    "\n",
    "ncores = os.cpu_count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "download_file() {\n",
    "    tax_db=$1\n",
    "    if [ ! -f \"${tax_db}.zip\" ]; then\n",
    "        curl -O ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump_archive/$tax_db.zip\n",
    "        unzip -d $tax_db $tax_db.zip\n",
    "        cd $tax_db\n",
    "        tar -czvf ../$tax_db.tar.gz *\n",
    "        cd ..\n",
    "        rm -rf $tax_db $tax_db.zip\n",
    "    fi\n",
    "}\n",
    "export -f download_file\n",
    "download_file \"new_taxdump_2019-01-01\" ## latest taxonomy release that still contains original virus taxonomy\n",
    "download_file \"new_taxdump_2019-06-01\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lca_analysis (input_file_name, output_dir, bucket_name, blast_type, default=False, ncores=8):\n",
    "    # First list the folders (there is a limit of 1000 files output by AWS by default)\n",
    "    list_of_folders = [client.list_objects(Bucket=bucket_name, Prefix=x[\"Prefix\"]+input_file_name) \\\n",
    "                       for x in client.list_objects(Bucket=bucket_name, Prefix=\"contigs/\", Delimiter=\"/\")[\"CommonPrefixes\"]]\n",
    "    list_of_folders = [\"s3://\"+bucket_name+\"/\"+x[\"Prefix\"] for x in list_of_folders if \"Contents\" in x.keys()]\n",
    "    filenames = pd.DataFrame(list_of_folders, columns=[\"blast_\"+blast_type])\n",
    "    output_string = output_dir\n",
    "    if not default:\n",
    "        output_string += \"/ident\"+str(ident_cutoff)+\"align\"+str(align_cutoff)+\"bitscore\"+str(bitscore_cutoff)\n",
    "    filenames = filenames.assign(filtered_blast=filenames[\"blast_\"+blast_type].str.replace(\"contigs\", output_string).str.replace(\".m9\", \"_filtered.m9\"))\n",
    "    filenames = filenames.assign(excluded_contigs=filenames[\"filtered_blast\"].apply(os.path.dirname).apply(lambda x: os.path.join(x, \"exclude_contigs_\"+blast_type+\".txt\")))\n",
    "    filenames = filenames.assign(lca=filenames[\"filtered_blast\"].str.replace(\"blast_\"+blast_type, \"lca_\"+blast_type).str.replace(\"_filtered\", \"\"))\n",
    "    filenames = filenames.assign(reads=filenames[\"blast_\"+blast_type].str.replace(\"blast_\"+blast_type+\".m9\", \"contig_stats.json\").replace(\"\"))\n",
    "    #filenames.loc[~filenames[\"reads\"].str.contains(\"ater\"), \"reads\"] = filenames.loc[~filenames[\"reads\"].str.contains(\"ater\"), \"reads\"].str.replace(\"bowtie\", \"Mos/bowtie\")\n",
    "    commands = filenames.apply(lambda x: \"python lca_analysis.py\"+\\\n",
    "                               \" --blast_type \"+blast_type+\\\n",
    "                               \" --fpath \"+x.iloc[0]+\\\n",
    "                               \" --filtered_blast_path \"+x.iloc[1]+\\\n",
    "                               \" --excluded_contigs_path \"+x.iloc[2]+\\\n",
    "                               \" --outpath \"+x.iloc[3]+\\\n",
    "                               \" --read_count_path \"+x.iloc[4]+\\\n",
    "                               \" --verbose True\", axis=1)\n",
    "    print (commands)\n",
    "    commands_csv_filename = \"lca_\"+blast_type+\"_commands\"\n",
    "    commands.to_csv(commands_csv_filename, index=False)\n",
    "    if (len(filenames) < ncores):\n",
    "        ncores = len(filenames)\n",
    "    command_str = \"parallel -a \"+commands_csv_filename+\" -j \"+str(ncores)\n",
    "    print (command_str)\n",
    "#     process = subprocess.Popen(command_str.split(), stdout=subprocess.PIPE)\n",
    "#     output, error = process.communicate()\n",
    "#     return (output, error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nt hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_lca_analysis(input_file_name=\"blast_nt.m9\", output_dir=\"contig_quality\", \\\n",
    "                 bucket_name=bucket_name, blast_type=\"nt\", default=True, ncores=ncores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_nt_paths = [\"s3://\"+bucket_name+\"/\"+x[\"Prefix\"]+\"lca_nt.m9\" \\\n",
    " for x in client.list_objects(Bucket=bucket_name, Prefix=\"contig_quality/\", Delimiter=\"/\")[\"CommonPrefixes\"] if \"Mos\" not in x[\"Prefix\"]]\n",
    "blast_nt_paths = [x.replace(\"lca_nt\", \"blast_nt_filtered\") for x in lca_nt_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: CMS001_Water5_RNA_A_S12\n",
      "error: CMS001_water1_S11\n",
      "error: CMS001_water5_RNA_A_S12\n",
      "error: CMS002_016a_Rb_S121_L004\n",
      "error: CMS002_025d_Rb_S143_L004\n",
      "error: CMS002_025f_Rb_S145_L004\n",
      "error: CMS002_0Water8_Rb_S11_L004\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lca_nt_paths)):\n",
    "    sample_name = os.path.basename(os.path.dirname(lca_nt_paths[i]))\n",
    "    outfile = lca_nt_paths[i].replace(\"lca_nt\", \"blast_lca_nt_filtered\")\n",
    "    try:\n",
    "        combine_blast_lca (lca_nt_paths[i], blast_nt_paths[i], outfile, sample_name, \"nt\")\n",
    "    except:\n",
    "        print (\"error: \"+sample_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nr hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract blast_nr hits from plast results and save to folder for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 ls s3://czbiohub-mosquito/plast/ | grep '.m8' | awk 'NF>1{print $NF}' | parallel -j 72 python create_blast_nr.py --fpath s3://czbiohub-mosquito/plast/{}\n",
    "aws s3 ls s3://lucymli/skeeters/blast_nr/ | grep 'CMS00' | awk 'NF>1{print $NF}' | parallel aws s3 sync s3://lucymli/skeeters/blast_nr/{} blast_nr_output/{}\n",
    "head -n 1 $(find blast_nr_output -type f -name '*.m8' | head -n 1) > header_line \n",
    "for x in `ls blast_nr_output`; do \n",
    "    mkdir -p blast_nr_output_full/$x\n",
    "    head -n 1 $(find blast_nr_output -type f -name '*.m8' | head -n 1) > blast_nr_output_full/$x/blast_nr.m9\n",
    "    ls -d $(find blast_nr_output/$x -type f) | xargs -0 -I file cat file > blast_nr_output_full/$x/blast_nr.m9\n",
    "done\n",
    "ls blast_nr_output_full | parallel aws s3 cp blast_nr_output_full/{}/blast_nr.m9 s3://czbiohub-mosquito/contigs/{}/blast_nr.m9\n",
    "\n",
    "# add missing taxids\n",
    "python initiate_gi2taxid_database.py\n",
    "aws s3 ls s3://czbiohub-mosquito/contigs/ --recursive | grep \"blast_nr.m9\" | awk 'NF>1{print $NF}' | parallel python get_missing_prot_taxa.py s3://czbiohub-mosquito/{}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_lca_analysis(input_file_name=\"blast_nr.m9\", output_dir=\"contig_quality\", \\\n",
    "                 bucket_name=bucket_name, blast_type=\"nr\", default=True, ncores=ncores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_nr_paths = [\"s3://\"+bucket_name+\"/\"+x[\"Prefix\"]+\"lca_nr.m9\" \\\n",
    " for x in client.list_objects(Bucket=bucket_name, Prefix=\"contig_quality/\", Delimiter=\"/\")[\"CommonPrefixes\"] if \"Mos\" not in x[\"Prefix\"]]\n",
    "blast_nr_paths = [x.replace(\"lca_nr\", \"blast_nr_filtered\") for x in lca_nr_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: CMS001_012_Ra_S4\n",
      "error: CMS001_Water5_RNA_A_S12\n",
      "error: CMS001_water1_S11\n",
      "error: CMS001_water5_RNA_A_S12\n",
      "error: CMS002_016a_Rb_S121_L004\n",
      "error: CMS002_025d_Rb_S143_L004\n",
      "error: CMS002_025f_Rb_S145_L004\n",
      "error: CMS002_053a_Rb_S7_L004\n",
      "error: CMS002_0Water8_Rb_S11_L004\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lca_nr_paths)):\n",
    "    sample_name = os.path.basename(os.path.dirname(lca_nr_paths[i]))\n",
    "    outfile = lca_nr_paths[i].replace(\"lca_nr\", \"blast_lca_nr_filtered\")\n",
    "    try:\n",
    "        combine_blast_lca (lca_nr_paths[i], blast_nr_paths[i], outfile, sample_name, \"nr\")\n",
    "    except:\n",
    "        print (\"error: \"+sample_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
